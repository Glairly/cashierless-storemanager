{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Drive"
      ],
      "metadata": {
        "id": "_6K_xUP79TXJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3KTAB21ynZn",
        "outputId": "d05321cd-6a9d-4519-d89b-c643871ac97a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dataset_path = \"/content/drive/MyDrive/cashierless-model\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLPRefVHcp-C"
      },
      "source": [
        "## Change to Python 3.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVWWFgYyQO9E"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uHThrpRcO2P",
        "outputId": "ba7bdfcc-9a5c-4800-b602-1b00dbbb9627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/conda\n",
            "conda 4.5.4\n",
            "/usr/local/bin/python\n",
            "Python 3.6.5 :: Anaconda, Inc.\n"
          ]
        }
      ],
      "source": [
        "!which conda # should return /usr/local/bin/conda\n",
        "\n",
        "!conda --version # should return 4.5.4\n",
        "\n",
        "!which python # still returns /usr/local/bin/python\n",
        "\n",
        "!python --version # now returns Python 3.6.5 :: Anaconda, Inc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqQ-ZP34u5Ck"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "conda install --channel defaults conda python=3.6 --yes\n",
        "\n",
        "conda update --channel defaults --all --yes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Re1iL1zgu5sP",
        "outputId": "cd098e3c-e9b1-48c8-9c3a-7f8292bf1533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conda 4.10.3\n",
            "Python 3.6.13 :: Anaconda, Inc.\n"
          ]
        }
      ],
      "source": [
        "!conda --version # now returns 4.8.3\n",
        "\n",
        "!python --version # now returns Python 3.6.10 :: Anaconda, Inc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TEoEzGKR1U0"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"/usr/local/lib/python3.6/site-packages\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tiy8eXlMTU3T"
      },
      "outputs": [],
      "source": [
        "!conda install tensorflow-gpu==1.15.0 --yes\n",
        "!conda install -c conda-forge tf_slim --yes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-zakOTN8jnV"
      },
      "outputs": [],
      "source": [
        "!pip install pillow\n",
        "!pip install lxml\n",
        "!pip install jupyter\n",
        "!pip install matplotlib\n",
        "!pip install pandas\n",
        "!pip install opencv-python\n",
        "!pip install cython\n",
        "!pip install scipy\n",
        "!pip install -q pycocotools\n",
        "!pip install lvis\n",
        "!pip install keras==2.1.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eWaWyBg7Npl"
      },
      "source": [
        "Sourch Example ->  https://muchamadsyaiffudin.medium.com/object-detection-with-custom-dataset-faster-rcnn-on-google-colab-33b373a625eb\n",
        "\n",
        "Guideline -> https://pub.towardsai.net/training-faster-r-cnn-using-tensorflow-object-detection-api-with-a-custom-dataset-88dd525666fd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6i0AW5Z8_Xx"
      },
      "outputs": [],
      "source": [
        "!apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "%set_env PYTHONPATH=/content/models/research:/content/models/research/slim\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += \":/content/models\"\n",
        "sys.path.append(\"/content/models\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CkowuS1870L3"
      },
      "outputs": [],
      "source": [
        "%cd /content/models/research/slim\n",
        "!python setup.py build\n",
        "!python setup.py install"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setup end here"
      ],
      "metadata": {
        "id": "02qQ5PPNH45j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daUHBtwODvIF"
      },
      "source": [
        "## Using Example Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ml_U85RUCh_B"
      },
      "outputs": [],
      "source": [
        "# %cd /content\n",
        "# %mkdir dataset\n",
        "# %cd /content/dataset\n",
        "\n",
        "\n",
        "# #!echo \"item {\\n id: 1\\n name: 'dog'\\n}\" > label_map.pbtxt\n",
        "\n",
        "# # shared fileid link for googledrive\n",
        "# fileId = '1xJMfIjUbFBlKoD-LZCaD0HKd62Z2JQrt'\n",
        "\n",
        "# import os\n",
        "# from zipfile import ZipFile\n",
        "# from shutil import copy\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)\n",
        "\n",
        "# fileName = fileId + '.zip'\n",
        "# downloaded = drive.CreateFile({'id': fileId})\n",
        "# downloaded.GetContentFile(fileName)\n",
        "# ds = ZipFile(fileName)\n",
        "# ds.extractall()\n",
        "# os.remove(fileName)\n",
        "# print('Extracted zip file ' + fileName)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download pre-trained model\n",
        "\n",
        "model_zoo : https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md"
      ],
      "metadata": {
        "id": "62HsNS0i8-de"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifW0b1xU_o7P"
      },
      "outputs": [],
      "source": [
        "# # Download pre-trained model\n",
        "\n",
        "# %mkdir $dataset_path/models\n",
        "# %cd $dataset_path/models\n",
        "\n",
        "# import os\n",
        "# import shutil\n",
        "# import glob\n",
        "# import urllib.request\n",
        "# import tarfile\n",
        "\n",
        "# MODEL = 'faster_rcnn_inception_v2_coco_2018_01_28'\n",
        "# MODEL_FILE = MODEL + '.tar.gz'\n",
        "# DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "# DEST_DIR = 'faster_rcnn_inception_v2'\n",
        "\n",
        "# # MODEL = 'faster_rcnn_resnet101_coco_2018_01_28'\n",
        "# # MODEL_FILE = MODEL + '.tar.gz'\n",
        "# # DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "# # DEST_DIR = 'faster_rcnn_resnet101'\n",
        "\n",
        "# #if not (os.path.exists(MODEL_FILE)):\n",
        "# #  opener = urllib.request.URLopener()\n",
        "# #  opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "# with urllib.request.urlopen(DOWNLOAD_BASE+MODEL_FILE) as response, open(MODEL_FILE, 'wb') as out_file:\n",
        "#   shutil.copyfileobj(response, out_file)\n",
        "\n",
        "# tar = tarfile.open(MODEL_FILE)\n",
        "# tar.extractall()\n",
        "# tar.close()\n",
        "\n",
        "# os.remove(MODEL_FILE)\n",
        "# if (os.path.exists(DEST_DIR)):\n",
        "#   shutil.rmtree(DEST_DIR)\n",
        "# os.rename(MODEL, DEST_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation"
      ],
      "metadata": {
        "id": "XgNVL_xVnQvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content\n",
        "git clone https://github.com/shubhbrth/Augmentation-for-VOC-Pascal.git\n",
        "pip install imgaug\n",
        "pip install pascal_voc_writer"
      ],
      "metadata": {
        "id": "abYBoSY-nQUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chagne INPUT_DIR and OUTPUT_DIR from augment.py in /content/Augmentation-for-VOC-Pascal as your prefer\n",
        "\n",
        "INPUT_DIR = '/content/drive/MyDrive/cashierless-model/images/train' <br>\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/cashierless-model/images/train-augmented'"
      ],
      "metadata": {
        "id": "oXlI881zqBS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/Augmentation-for-VOC-Pascal\n",
        "rm -rf /content/drive/MyDrive/cashierless-model/images/train-augmented/*\n",
        "python augment.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDudSc2hoM_C",
        "outputId": "207ec362-5894-4ef2-c524-96094ecf9c8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmenting input/apple.xml ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.6/site-packages/imgaug/imgaug.py:184: DeprecationWarning: Method `BoundingBoxesOnImage.cut_out_of_image()` is deprecated. Use `BoundingBoxesOnImage.clip_out_of_image()` instead. clip_out_of_image() has the exactly same interface.\n",
            "  warn_deprecated(msg, stacklevel=3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TgucU5GG4sV"
      },
      "source": [
        "## Converting the prepared dataset’s XML files to CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxbuEi2ZG8C6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "\n",
        "def main():\n",
        "  for directory in ['train-augmented','test']:\n",
        "    image_path = os.path.join(os.getcwd(), 'images/{}'.format(directory))\n",
        "    xml_df = xml_to_csv(image_path)\n",
        "    if directory == \"train-augmented\":\n",
        "        xml_df.to_csv('data/train_labels.csv')\n",
        "    else:\n",
        "        xml_df.to_csv('data/test_labels.csv')\n",
        "\n",
        "    print('Successfully converted xml to csv.')\n",
        "\n",
        "%cd $dataset_path\n",
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zZTsiy47IXB"
      },
      "source": [
        "## Create Tf_Record"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTHeRQKE5nzk",
        "outputId": "d0dbfe37-65ba-423c-a0d8-c52872cdf7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/cashierless-model\n",
            "WARNING:tensorflow:From generate_tfrecord.py:104: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:90: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1004 17:09:01.300842 139795468318592 module_wrapper.py:139] From generate_tfrecord.py:90: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/drive/MyDrive/cashierless-model/data/train.record\n",
            "WARNING:tensorflow:From generate_tfrecord.py:104: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:90: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W1004 17:09:05.212046 140562067060608 module_wrapper.py:139] From generate_tfrecord.py:90: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From generate_tfrecord.py:49: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W1004 17:09:06.049685 140562067060608 module_wrapper.py:139] From generate_tfrecord.py:49: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created the TFRecords: /content/drive/MyDrive/cashierless-model/data/test.record\n"
          ]
        }
      ],
      "source": [
        "%cd $dataset_path\n",
        "\n",
        "!python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=data/train.record --image_dir=images/train-augmented\n",
        "\n",
        "!python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=data/test.record --image_dir=images/test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYaC-Qev-fNh"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCfejxIbCKkU",
        "outputId": "6c4ac1b6-0d83-4619-aa3e-9bb8da34a5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/research\n"
          ]
        }
      ],
      "source": [
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kayJG7Z97p2-"
      },
      "outputs": [],
      "source": [
        "%cd /content/models/research/object_detection/\n",
        "\n",
        "model_dir = dataset_path + \"/models/training\"\n",
        "pipeline_config_path= dataset_path + \"/data/faster_rcnn_resnet101.config\"\n",
        "!python model_main.py \\\n",
        "!  --model_dir=$model_dir \\\n",
        "!  --num_train_steps=20000 \\\n",
        "!  --pipeline_config_path=$pipeline_config_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clXNKPmaxusr"
      },
      "source": [
        "## Export"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5N69UwOi7pwl"
      },
      "outputs": [],
      "source": [
        "%cd /content/models/research/object_detection\n",
        "trained_checkpoint_prefix= dataset_path + \"/models/model.ckpt-20000\"\n",
        "output_dir = dataset_path + \"/inference_graph\"\n",
        "%rm -r $output_dir\n",
        "!python export_inference_graph.py --input_type image_tensor --pipeline_config_path=$pipeline_config_path --trained_checkpoint_prefix=$trained_checkpoint_prefix --output_directory=$output_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF6HNjQ5pap6"
      },
      "source": [
        "## Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we_SwnIve1kv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "from object_detection.core import post_processing\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from PIL import ImageFont\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByiSkunI3QbQ",
        "outputId": "33f8a7d6-945b-4317-f7cb-784a6421700c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor 'image_tensor:0' shape=(None, None, None, 3) dtype=uint8>]\n"
          ]
        }
      ],
      "source": [
        "model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "detection_model  = tf.saved_model.load(output_dir + \"/saved_model\")\n",
        "print(detection_model.signatures['serving_default'].inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7pOvxerug49"
      },
      "outputs": [],
      "source": [
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  # Run inference\n",
        "  model_fn = model.signatures['serving_default']\n",
        "  output_dict = model_fn(input_tensor)\n",
        "\n",
        "  # All outputs are batches tensors.\n",
        "  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
        "  # We're only interested in the first num_detections.\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  # detection_classes should be ints.\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "\n",
        "  # Apply NMS\n",
        "  boxes = tf.constant(np.expand_dims(output_dict[\"detection_boxes\"],axis=1))\n",
        "  scores = tf.constant(np.array(output_dict[\"detection_multiclass_scores\"]))\n",
        "  nms,_ = post_processing.multiclass_non_max_suppression(\n",
        "                                          boxes,\n",
        "                                          scores,\n",
        "                                          score_thresh=0.5,\n",
        "                                          iou_thresh=0.5,\n",
        "                                          max_size_per_class=1)\n",
        "  boxes,scores,classes = (nms.get(), nms.get_field(\"scores\"), nms.get_field(\"classes\"))\n",
        "\n",
        "  # Remove N/A boxes at the 1st element\n",
        "  output_dict['detection_boxes'] = boxes.numpy()[1:]\n",
        "  output_dict['detection_scores'] = scores.numpy()[1:]\n",
        "  output_dict['detection_classes'] = (classes).numpy().astype(np.int64)[1:]\n",
        "   \n",
        "  # Handle models with masks:\n",
        "  if 'detection_masks' in output_dict:\n",
        "    # Reframe the the bbox mask to the image size.\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])      \n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "    \n",
        "  return output_dict\n",
        "\n",
        "def show_inference(model, image_path):\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = np.array(Image.open(image_path))\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      min_score_thresh=.5,\n",
        "      line_thickness=8)\n",
        "\n",
        "  display(Image.fromarray(image_np).resize(size=(600,600)))\n",
        "  return output_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_RvA109vegs"
      },
      "outputs": [],
      "source": [
        "PATH_TO_TEST_IMAGES_DIR = dataset_path + '/images/validate'\n",
        "TEST_IMAGE_PATHS = [\"1.webp\",\"2.jpg\",\"3.jpg\",\"4.jpg\",\"5.webp\",\"6.jpg\",\"7.jpg\",\"8.jpg\",\"9.jpg\",\"10.jpg\",\"11.jpg\",\"12.jpg\",\"14.jpg\"]\n",
        "# TEST_IMAGE_PATHS = [\"☘ (1).jpg\"]\n",
        "PATH_TO_LABELS = dataset_path + '/data/object-detection.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "o_dict = ''\n",
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  o_dict = show_inference(detection_model, PATH_TO_TEST_IMAGES_DIR + \"/\" + image_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U5RzWSKO7KaT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}